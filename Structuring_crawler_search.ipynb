{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb064b2-f8bb-4d84-9ce2-d3f965791d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4e95e-39bf-4cb3-8819-abcee81f9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    \"\"\"Common base class for all article/pages\"\"\"\n",
    "\n",
    "    def __init__(self, topic, url, title, body):\n",
    "        self.topic = topic\n",
    "        self.url = url\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "\n",
    "    def print(self):\n",
    "        print('New article found for topic: {}'.format(self.topic))\n",
    "        print('URL: {}'.format(self.url))\n",
    "        print('Title: {}'.format(self.title))\n",
    "        print('Body:\\n{}'.format(self.body))\n",
    "\n",
    "\n",
    "class Website:\n",
    "    \"\"\"Contains information about website structure\"\"\"\n",
    "\n",
    "    def __init___(self, name, url, searchUrl, resultListing, resultUrl, absoluteUrl,\n",
    "                  titleTag, bodyTag):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.searchUrl = searchUrl\n",
    "        self.resultListing = resultListing\n",
    "        self.resultUrl = resultUrl\n",
    "        self.absoluteUrl = absoluteUrl\n",
    "        self.titleTag = titleTag\n",
    "        self.bodyTag = bodyTag\n",
    "\n",
    "\n",
    "class Crawler:\n",
    "    def __init__(self, website):\n",
    "        self.site = website\n",
    "        self.found = {}\n",
    "\n",
    "\n",
    "    def getPage(url):\n",
    "        try:\n",
    "            html = urlopen(url)\n",
    "        except Exception:\n",
    "            return None\n",
    "        return BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "    def safeGet(bs, selector):\n",
    "        selectedElems = bs.select(selector)\n",
    "        if selectedElems is not None and len(selectedElems) > 0:\n",
    "            return '\\n'.join([elem.get_text() for elem in selectedElems])\n",
    "        return ''\n",
    "\n",
    "    def getContent(self, topic, url):\n",
    "        \"\"\"Extract content from a given page URL\"\"\"\n",
    "\n",
    "        bs = Crawler.getPage(url)\n",
    "        if bs is not None:\n",
    "            title = Crawler.safeGet(bs, self.site.titleTag)\n",
    "            body = Crawler.safeGet(bs, self.site.bodyTag)\n",
    "            return Content(topic, url, title, body)    \n",
    "        return Content(topic, url, '', '')\n",
    "\n",
    "    def search(self, topic):\n",
    "        bs = Crawler.getPage(self.site.searchUrl + topic)\n",
    "        searchResults = bs.select(self.site.resultListing)\n",
    "        for result in searchResults:\n",
    "            url = result.select(self.site.resultUrl)[0].attrs['href']\n",
    "            url = url if self.site.absoluteUrl else self.site.url + url\n",
    "            if url not in self.found:\n",
    "                self.found[url] = self.getContent(topic, url)\n",
    "            self.found[url].print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e856c9-77aa-42b6-b680-e13b51e67b8a",
   "metadata": {},
   "source": [
    "# Crawling Sites Through Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eff31a-a1ad-44c5-9a9f-019024d2e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, name, url, targetPattern, absoluteUrl, titleTag, bodyTag):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.targetPattern = targetPattern\n",
    "        self.absoluteUrl = absoluteUrl\n",
    "        self.titleTag = titleTag\n",
    "        self.bodyTag = bodyTag\n",
    "\n",
    "class Content:\n",
    "    def __init__(self, url, title, body):\n",
    "        self.url = url\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "\n",
    "    def print():\n",
    "        print(f'url: {self.url}')\n",
    "        print(f'title: {self.title}')\n",
    "        print(f'body:\\n{self.body}')\n",
    "\n",
    "class Crawler:\n",
    "    def __init__(self, site):\n",
    "        self.site = site\n",
    "        self.visited = {}\n",
    "\n",
    "    def getPage(url):\n",
    "        try:\n",
    "            html = urlopen(url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "        return BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    def safeGet(bs, selector):\n",
    "        selectedElems = bs.select(selector)\n",
    "        if selectedElems is not None and len(selectedElems) > 0:\n",
    "            return '\\n'.join([elem.get_text() for elem in selectedElems])\n",
    "        return ''\n",
    "\n",
    "    def getContent(self, url):\n",
    "        bs = Crawler.getPage(url)\n",
    "        if bs is not None:\n",
    "            title = Crawler.safeGet(bs, self.site.titleTag)\n",
    "            body = Crawler.safeGet(bs, self.site.bodyTag)\n",
    "            return Content(url, title, body)\n",
    "        return Content(url, '', '')\n",
    "\n",
    "    def crawl(self):\n",
    "        bs = Crawler.getPage(self.site.url)\n",
    "        targetPages = bs.find_all('a', href=re.compile(self.site.targetPattern))\n",
    "        for targetPage in targetPages:\n",
    "            url = targetPage.attrs['href']\n",
    "            url = url if self.site.absoluteUrl else self.site.url + url\n",
    "            if url not in self.visited:\n",
    "                self.visited['url'] = self.getContent(url)\n",
    "                self.visited['url'].print()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
